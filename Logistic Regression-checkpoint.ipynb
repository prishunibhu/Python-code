{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logistic Regression notes from 25 Sep 2021\n",
    "\n",
    "\n",
    "It is a classification algo and is used for dichotomous prediction - yes/no\n",
    "\n",
    "It works on the probability concepts\n",
    "\n",
    "It can have continous and discrete data.\n",
    "\n",
    "The output is determined by the probability and building a linear algebra line.\n",
    "\n",
    "Inputs can be qualitative or quantitative and if it is qualitative convert to quantitative.\n",
    "\n",
    "Step 1:\n",
    "    \n",
    "Make a linear line for the data\n",
    "\n",
    "p(x)=B1x+B0\n",
    "\n",
    "But the problem is now p(x) can be any value and is unbounded. However for probability we need to limit between 0 and 1\n",
    "\n",
    "There we introduce log odds and sigmoids\n",
    "    \n",
    "odds= chances true / chances false.\n",
    "\n",
    "\n",
    "log(p(x) = B0 + B1x\n",
    "\n",
    "Now with this, we have a lower bound of 0 and upper bound infinite. Therefore we again introduce sigmoid  which gives us\n",
    "    \n",
    "p(x) = e^(B0+b1x) / 1+ e*^(B0+B1x)\n",
    "    \n",
    "This above equation helps us to give the probability betweeen 0 and 1 and thereby helps to do the prediction.\n",
    "    \n",
    "which can be re written as\n",
    "    \n",
    "log(p(x)/1-p(x)) = B0+B1x\n",
    "    \n",
    "LHS is called odds ratio.\n",
    "\n",
    "\n",
    "\n",
    "Now B0 and B1 is defined as - > Prod of(( p(xi) ^ yi ) * (1-p(xi)) ^ (1-yi))\n",
    "\n",
    "or \n",
    "    \n",
    "B0,B1= sum(y log (p(X)) + y-1 log(1-p(x))\n",
    "\n",
    "https://www.kdnuggets.com/2018/02/logistic-regression-concise-technical-overview.html\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "and thse B0 and B1 should be maximized for the model to work well and this is my objective. \n",
    "    \n",
    "In my train set, apply the probs and find B0,B1 and then apply the B0,B1 value to sigmoid function to predict the probabiliy.\n",
    "           \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "p(x) = e^ log(odds)/ 1+ e^ log(odds)\n",
    "\n",
    "Likelihood:\n",
    "    \n",
    "It is the prob value for each prediction.\n",
    "\n",
    "find the total value of prob which is  likelihood of all values\n",
    "\n",
    "which is sum p(x) *  x\n",
    "and take of the log of the functions\n",
    "\n",
    "= sum ( log (p(x) * x)\n",
    "       \n",
    "The maximum values of log likehood is taken are the best fitted line\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_heart=pd.read_csv(\"heart.csv\")\n",
    "df_heart.head(5)\n",
    "x=pd.DataFrame(df_heart.iloc[:,:-1])\n",
    "y=pd.DataFrame(df_heart.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(205, 13)\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=1)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Priyadarshini\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\Priyadarshini\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Regressor = LogisticRegression()\n",
    "Regressor.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 0 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 1 0 0 0 1 1 0 1 0 1 1 0 0 1 1 1 1\n",
      " 0 0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 0 1 1 0 0 1 1 1 0 0 1\n",
      " 1 0 1 0 1 0 0 1 1 1 0 0 1 0 1 0 1 0 1 1 0 0 1 1 1 0 1 1 1 0 1 1 0 1 1 0 0\n",
      " 1 0 1 1 1 0 1 1 1 0 0 0 0 1 0 1 1 1 1 0 0 0 0 1 1 0 0 1 1 0 0 0 1 0 1 1 1\n",
      " 0 1 1 1 0 0 0 1 0 1 1 0 1 1 1 1 0 0 1 1 0 1 1 0 1 0 1 1 1 1 0 0 0 1 1 0 0\n",
      " 0 1 0 1 1 1 1 0 0 0 1 1 0 0 1 1 0 0 1 0]\n",
      "0.8048780487804879\n"
     ]
    }
   ],
   "source": [
    "y_pred=Regressor.predict(x_test)\n",
    "print(y_pred)\n",
    "print(Regressor.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scoreaccuracy_score 0.8048780487804879\n"
     ]
    }
   ],
   "source": [
    "accuracy=Regressor.score(x_test,y_test)\n",
    "print(\"Accuracy scoreaccuracy_score\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix [[80 11]\n",
      " [29 85]]\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix for classification\n",
    "\n",
    "confusion=confusion_matrix(y_pred,y_test)\n",
    "print(\"Confusion matrix\",confusion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
